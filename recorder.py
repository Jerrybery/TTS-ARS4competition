import sounddevice as sd
import numpy as np
import wave
import time
import os

SAMPLE_RATE = 16000
CHANNELS = 1
SILENCE_THRESHOLD = 1.5  # é™éŸ³å¤šå°‘ç§’ååœæ­¢
SILENCE_DURATION = 0.1  # å‰100msé‡‡æ ·é™éŸ³èƒ½é‡
ENERGY_OFFSET = 14000     # é˜ˆå€¼åç§»é‡

def record_until_silence():
    buffer = []
    recording = False
    last_voice_time = None
    silence_energy = []
    output_file = f"paddleASR/audio/sound_{time.strftime('%Y-%m-%d %H:%M:%S')}.wav"

    def silence_callback(indata, frames, cb_time, status):
        nonlocal silence_energy
        energy = np.sum(indata.astype(np.float32) ** 2) / len(indata)
        silence_energy.append(energy)

    print("é‡‡é›†é™éŸ³èƒ½é‡åŸºçº¿...")
    with sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        dtype="int16",
        callback=silence_callback
    ):
        time.sleep(SILENCE_DURATION)
    base_energy = np.mean(silence_energy)
    ENERGY_THRESHOLD = base_energy + ENERGY_OFFSET
    print(f"é™éŸ³èƒ½é‡å‡å€¼: {base_energy:.2f}, é˜ˆå€¼è®¾ä¸º: {ENERGY_THRESHOLD:.2f}")

    def callback(indata, frames, cb_time, status):
        nonlocal buffer, recording, last_voice_time
        energy = np.sum(indata.astype(np.float32) ** 2) / len(indata)
        # print(energy)
        if energy > ENERGY_THRESHOLD:
            if not recording:
                print("ğŸ¤ æ£€æµ‹åˆ°äººå£°ï¼Œå¼€å§‹å½•éŸ³...")
                recording = True
            last_voice_time = time.time()
            buffer.append(indata.copy())
        elif recording:
            buffer.append(indata.copy())

    print("ç­‰å¾…äººå£°è¾“å…¥...")
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        dtype="int16",
        callback=callback
    ):
        while True:
            if recording and last_voice_time is not None:
                current_time = time.time()
                if current_time - last_voice_time > SILENCE_THRESHOLD:
                    print("ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼Œåœæ­¢å½•éŸ³")
                    break
            time.sleep(0.1)

    if buffer:
        audio_data = np.concatenate(buffer)
        with wave.open(output_file, "wb") as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(2)
            wf.setframerate(SAMPLE_RATE)
            wf.writeframes(audio_data.tobytes())
        print(f"âœ… å½•éŸ³å·²ä¿å­˜è‡³ {output_file}")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œæœªä¿å­˜æ–‡ä»¶")

if __name__ == "__main__":
    record_until_silence()
